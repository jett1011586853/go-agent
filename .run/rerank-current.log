
===================================
== NVIDIA NIM for Text Reranking ==
===================================

NVIDIA Release 1.8.0
Model: nvidia/llama-3.2-nv-rerankqa-1b-v2

Container image Copyright (c) 2016-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
The NIM container is governed by the NVIDIA Software License Agreement (found at https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/) and the Product-Specific Terms for NVIDIA AI Products (found at https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/).

Use of this model is governed by the NVIDIA Community Model License Agreement (found at https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-community-models-license/).

ADDITIONAL INFORMATION: Llama 3.2 Community License Agreement (https://www.llama.com/llama3_2/license/). Built with Llama.

A copy of this license can be found under /opt/nim/LICENSE.
Third Party Software Attributions and Licenses can be found under /opt/nim/acknowledgements.txt.

Overriding NIM_LOG_LEVEL: replacing NIM_LOG_LEVEL=unset with NIM_LOG_LEVEL=INFO
HF_HOME is set to /opt/nim/.cache/huggingface
INFO 2026-02-27 18:23:57.846 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/opt/nim/start_server.d', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
NIM_MODEL_PROFILE is set to bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-27 18:23:58.447 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/opt/nim/start_server.d', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
INFO 2026-02-27 18:24:00.388 profiles.py:98] Registered custom profile selectors: []
INFO 2026-02-27 18:24:00.388 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-27 18:24:00.388 nim_sdk.py:299] Using the profile selected by the profile selector: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-27 18:24:00.388 nim_sdk.py:308] Downloading manifest profile: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-27 18:24:00.433 lib.rs:203] File: tokenizer.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-27 18:24:00.434 public.rs:52] Skipping download, using cached copy of file: tokenizer.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-27 18:24:00.451 lib.rs:203] File: memory_footprint.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-27 18:24:00.451 public.rs:52] Skipping download, using cached copy of file: memory_footprint.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-27 18:24:00.467 lib.rs:203] File: metadata.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-27 18:24:00.467 public.rs:52] Skipping download, using cached copy of file: metadata.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-27 18:24:00.481 tokio.rs:919] "nim/nvidia/llama-3.2-nv-rerankqa-1b-v2:l40sx1-trt-fp8-lwpgyxqy1w": fetching filemap from: https://api.ngc.nvidia.com/v2/org/nim/team/nvidia/models/llama-3.2-nv-rerankqa-1b-v2/l40sx1-trt-fp8-lwpgyxqy1w/files
INFO 2026-02-27 18:24:00.497 lib.rs:203] File: special_tokens_map.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-27 18:24:00.497 public.rs:52] Skipping download, using cached copy of file: special_tokens_map.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-27 18:24:00.515 lib.rs:203] File: tokenizer_config.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-27 18:24:00.515 public.rs:52] Skipping download, using cached copy of file: tokenizer_config.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-27 18:24:00.531 lib.rs:203] File: checksums.blake3 found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
INFO 2026-02-27 18:24:00.531 public.rs:52] Skipping download, using cached copy of file: checksums.blake3 at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
model.plan [00:00:00] [░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 0 B/1.54 GiB 0 B/s (0s)
[2Kmodel.plan [00:08:57] [░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10.31 MiB/1.54 GiB 19.62 KiB/s (23h)
[2Kmodel.plan [00:11:49] [█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 26.31 MiB/1.54 GiB 95.25 KiB/s (5h)
[2Kmodel.plan [00:12:15] [███░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 42.31 MiB/1.54 GiB 618.15 KiB/s (42m)
[2Kmodel.plan [00:12:16] [████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 58.31 MiB/1.54 GiB 963.37 KiB/s (27m)
[2Kmodel.plan [00:12:35] [█████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 74.31 MiB/1.54 GiB 975.14 KiB/s (26m)
[2Kmodel.plan [00:12:41] [██████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 90.31 MiB/1.54 GiB 1.58 MiB/s (16m)
[2Kmodel.plan [00:12:46] [███████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 106.31 MiB/1.54 GiB 2.13 MiB/s (12m)
[2Kmodel.plan [00:12:47] [█████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 122.31 MiB/1.54 GiB 2.41 MiB/s (10m)
[2Kmodel.plan [00:12:50] [██████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 138.31 MiB/1.54 GiB 3.32 MiB/s (7m)
[2Kmodel.plan [00:12:51] [███████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 154.31 MiB/1.54 GiB 3.79 MiB/s (6m)
[2Kmodel.plan [00:13:04] [████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 170.31 MiB/1.54 GiB 2.18 MiB/s (11m)
[2Kmodel.plan [00:13:06] [██████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 186.31 MiB/1.54 GiB 2.48 MiB/s (9m)
[2Kmodel.plan [00:13:07] [███████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 202.31 MiB/1.54 GiB 3.06 MiB/s (7m)
[2Kmodel.plan [00:13:10] [████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 218.31 MiB/1.54 GiB 3.84 MiB/s (6m)
[2Kmodel.plan [00:13:15] [█████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 234.31 MiB/1.54 GiB 4.12 MiB/s (5m)
[2Kmodel.plan [00:13:16] [██████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 250.31 MiB/1.54 GiB 4.45 MiB/s (5m)
[2Kmodel.plan [00:13:17] [████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 266.31 MiB/1.54 GiB 4.72 MiB/s (5m)
[2Kmodel.plan [00:13:18] [█████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 282.31 MiB/1.54 GiB 5.13 MiB/s (4m)
[2Kmodel.plan [00:13:28] [██████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 298.31 MiB/1.54 GiB 3.52 MiB/s (6m)
[2Kmodel.plan [00:13:29] [███████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 314.31 MiB/1.54 GiB 3.67 MiB/s (6m)
[2Kmodel.plan [00:13:29] [████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 330.31 MiB/1.54 GiB 4.09 MiB/s (5m)
[2Kmodel.plan [00:13:33] [██████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 346.31 MiB/1.54 GiB 4.80 MiB/s (4m)
[2Kmodel.plan [00:13:33] [███████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 362.31 MiB/1.54 GiB 4.86 MiB/s (4m)
[2Kmodel.plan [00:13:34] [████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 378.31 MiB/1.54 GiB 5.11 MiB/s (4m)
[2Kmodel.plan [00:13:34] [█████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 394.31 MiB/1.54 GiB 5.27 MiB/s (4m)
[2Kmodel.plan [00:13:34] [██████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 410.31 MiB/1.54 GiB 6.09 MiB/s (3m)
[2Kmodel.plan [00:13:36] [████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 426.31 MiB/1.54 GiB 7.61 MiB/s (3m)
[2Kmodel.plan [00:13:37] [█████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 442.31 MiB/1.54 GiB 8.06 MiB/s (2m)
[2Kmodel.plan [00:13:40] [██████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 458.31 MiB/1.54 GiB 8.85 MiB/s (2m)
[2Kmodel.plan [00:13:41] [███████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 474.31 MiB/1.54 GiB 9.04 MiB/s (2m)
[2Kmodel.plan [00:13:43] [████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 490.31 MiB/1.54 GiB 9.48 MiB/s (2m)
[2Kmodel.plan [00:13:45] [██████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 506.31 MiB/1.54 GiB 9.55 MiB/s (2m)
[2Kmodel.plan [00:13:46] [███████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 522.31 MiB/1.54 GiB 9.65 MiB/s (2m)
[2Kmodel.plan [00:13:47] [████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 538.31 MiB/1.54 GiB 9.81 MiB/s (2m)
[2Kmodel.plan [00:13:49] [█████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 554.31 MiB/1.54 GiB 9.92 MiB/s (2m)
[2Kmodel.plan [00:13:54] [██████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 570.31 MiB/1.54 GiB 8.37 MiB/s (2m)
[2Kmodel.plan [00:13:55] [████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 586.31 MiB/1.54 GiB 8.38 MiB/s (2m)
[2Kmodel.plan [00:13:55] [█████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 602.31 MiB/1.54 GiB 8.43 MiB/s (2m)
[2Kmodel.plan [00:13:55] [██████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 618.31 MiB/1.54 GiB 8.52 MiB/s (2m)
[2Kmodel.plan [00:13:57] [███████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 634.31 MiB/1.54 GiB 9.35 MiB/s (2m)
[2Kmodel.plan [00:13:57] [█████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 650.31 MiB/1.54 GiB 9.44 MiB/s (2m)
[2Kmodel.plan [00:13:58] [█████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 666.31 MiB/1.54 GiB 10.08 MiB/s (2m)
[2Kmodel.plan [00:13:59] [██████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 682.31 MiB/1.54 GiB 10.78 MiB/s (83s)
[2Kmodel.plan [00:13:59] [███████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 698.31 MiB/1.54 GiB 11.08 MiB/s (79s)
[2Kmodel.plan [00:13:59] [████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 714.31 MiB/1.54 GiB 11.23 MiB/s (77s)
[2Kmodel.plan [00:14:00] [██████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 730.31 MiB/1.54 GiB 12.09 MiB/s (70s)
[2Kmodel.plan [00:14:01] [███████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 746.31 MiB/1.54 GiB 12.62 MiB/s (66s)
[2Kmodel.plan [00:14:02] [████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 762.31 MiB/1.54 GiB 13.57 MiB/s (60s)
[2Kmodel.plan [00:14:03] [█████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 778.31 MiB/1.54 GiB 14.12 MiB/s (57s)
[2Kmodel.plan [00:14:03] [██████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 794.31 MiB/1.54 GiB 14.55 MiB/s (54s)
[2Kmodel.plan [00:14:03] [████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 810.31 MiB/1.54 GiB 14.69 MiB/s (52s)
[2Kmodel.plan [00:14:03] [█████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 826.31 MiB/1.54 GiB 14.88 MiB/s (51s)
[2Kmodel.plan [00:14:04] [██████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 842.31 MiB/1.54 GiB 15.10 MiB/s (49s)
[2Kmodel.plan [00:14:04] [███████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 858.31 MiB/1.54 GiB 16.10 MiB/s (45s)
[2Kmodel.plan [00:14:05] [████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 874.31 MiB/1.54 GiB 16.54 MiB/s (43s)
[2Kmodel.plan [00:14:05] [█████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 890.31 MiB/1.54 GiB 17.16 MiB/s (40s)
[2Kmodel.plan [00:14:09] [███████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 906.31 MiB/1.54 GiB 17.14 MiB/s (39s)
[2Kmodel.plan [00:14:09] [████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 922.31 MiB/1.54 GiB 17.22 MiB/s (38s)
[2Kmodel.plan [00:14:10] [█████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 938.31 MiB/1.54 GiB 17.40 MiB/s (37s)
[2Kmodel.plan [00:14:10] [██████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 954.31 MiB/1.54 GiB 17.48 MiB/s (36s)
[2Kmodel.plan [00:14:10] [███████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 970.31 MiB/1.54 GiB 17.60 MiB/s (35s)
[2Kmodel.plan [00:14:10] [█████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 986.31 MiB/1.54 GiB 18.03 MiB/s (33s)
[2Kmodel.plan [00:14:11] [█████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1002.31 MiB/1.54 GiB 18.76 MiB/s (31s)
[2Kmodel.plan [00:14:12] [██████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1018.31 MiB/1.54 GiB 18.90 MiB/s (30s)
[2Kmodel.plan [00:14:12] [█████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.01 GiB/1.54 GiB 19.08 MiB/s (29s)
[2Kmodel.plan [00:14:13] [███████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.03 GiB/1.54 GiB 20.00 MiB/s (26s)
[2Kmodel.plan [00:14:14] [████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.04 GiB/1.54 GiB 20.33 MiB/s (25s)
[2Kmodel.plan [00:14:14] [█████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.06 GiB/1.54 GiB 20.56 MiB/s (24s)
[2Kmodel.plan [00:14:15] [██████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.07 GiB/1.54 GiB 21.01 MiB/s (23s)
[2Kmodel.plan [00:14:16] [████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.09 GiB/1.54 GiB 21.42 MiB/s (22s)
[2Kmodel.plan [00:14:16] [█████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.10 GiB/1.54 GiB 21.62 MiB/s (21s)
[2Kmodel.plan [00:14:17] [██████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.12 GiB/1.54 GiB 21.84 MiB/s (20s)
[2Kmodel.plan [00:14:17] [███████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.14 GiB/1.54 GiB 21.93 MiB/s (19s)
[2Kmodel.plan [00:14:17] [████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.15 GiB/1.54 GiB 22.05 MiB/s (18s)
[2Kmodel.plan [00:14:18] [██████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.17 GiB/1.54 GiB 22.24 MiB/s (17s)
[2Kmodel.plan [00:14:19] [███████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.18 GiB/1.54 GiB 22.97 MiB/s (16s)
[2Kmodel.plan [00:14:21] [████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░���░░░░░] 1.20 GiB/1.54 GiB 22.48 MiB/s (16s)
[2Kmodel.plan [00:14:21] [█████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░░] 1.21 GiB/1.54 GiB 22.49 MiB/s (15s)
[2Kmodel.plan [00:14:22] [██████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░░░] 1.23 GiB/1.54 GiB 22.52 MiB/s (14s)
[2Kmodel.plan [00:14:23] [████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░░] 1.24 GiB/1.54 GiB 22.32 MiB/s (14s)
[2Kmodel.plan [00:14:23] [█████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░░] 1.26 GiB/1.54 GiB 22.34 MiB/s (13s)
[2Kmodel.plan [00:14:23] [██████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░░] 1.28 GiB/1.54 GiB 22.46 MiB/s (12s)
[2Kmodel.plan [00:14:24] [███████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░░] 1.29 GiB/1.54 GiB 22.58 MiB/s (11s)
[2Kmodel.plan [00:14:24] [████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░░░] 1.31 GiB/1.54 GiB 22.84 MiB/s (11s)
[2Kmodel.plan [00:14:24] [██████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░░] 1.32 GiB/1.54 GiB 22.96 MiB/s (10s)
[2Kmodel.plan [00:14:25] [████████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░░] 1.34 GiB/1.54 GiB 23.22 MiB/s (9s)
[2Kmodel.plan [00:14:25] [█████████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░░] 1.35 GiB/1.54 GiB 23.74 MiB/s (8s)
[2Kmodel.plan [00:14:25] [██████████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░░] 1.37 GiB/1.54 GiB 24.11 MiB/s (7s)
[2Kmodel.plan [00:14:26] [███████████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░░░] 1.39 GiB/1.54 GiB 24.32 MiB/s (7s)
[2Kmodel.plan [00:14:26] [█████████████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░░] 1.40 GiB/1.54 GiB 25.02 MiB/s (6s)
[2Kmodel.plan [00:14:27] [██████████████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░░] 1.42 GiB/1.54 GiB 25.41 MiB/s (5s)
[2Kmodel.plan [00:14:27] [███████████████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░░] 1.43 GiB/1.54 GiB 25.68 MiB/s (4s)
[2Kmodel.plan [00:14:27] [████████████████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░░] 1.45 GiB/1.54 GiB 26.05 MiB/s (4s)
[2Kmodel.plan [00:14:27] [█████████████████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░░░] 1.46 GiB/1.54 GiB 26.42 MiB/s (3s)
[2Kmodel.plan [00:14:28] [███████████████████████████████████████████████████████████████████████████████████████████████████████████████████░░░░░] 1.48 GiB/1.54 GiB 26.73 MiB/s (2s)
[2Kmodel.plan [00:14:28] [████████████████████████████████████████████████████████████████████████████████████████████████████████████████████░░░░] 1.49 GiB/1.54 GiB 27.23 MiB/s (2s)
[2Kmodel.plan [00:14:28] [█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████░░░] 1.51 GiB/1.54 GiB 27.50 MiB/s (1s)
[2Kmodel.plan [00:14:28] [██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████░░] 1.53 GiB/1.54 GiB 28.22 MiB/s (1s)
[2Kmodel.plan [00:14:29] [████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████] 1.54 GiB/1.54 GiB 28.63 MiB/s (0s)
[2Kmodel.plan [00:14:29] [█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████] 1.54 GiB/1.54 GiB 1.82 MiB/s (0s)INFO 2026-02-27 18:38:32.003 tokio.rs:814] Downloaded filename: model.plan to blob: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/blobs/6a25cabed12a56dfe9323d191e27bce5-4"
INFO 2026-02-27 18:38:32.023 nim_sdk.py:328] Using the workspace specified during init: /opt/nim/workspace
INFO 2026-02-27 18:38:32.024 nim_sdk.py:341] Materializing workspace to: /opt/nim/workspace
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
INFO 2026-02-27 18:38:37.499 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
2026-02-27T18:38:37Z INFO: nimlib - Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
INFO 2026-02-27 18:38:37.905 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:38:37Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-27 18:38:37.905 nim_sdk.py:294] Using the profile specified by the user: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:38:37Z INFO: nimlib.nim_sdk - Using the profile specified by the user: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-27 18:38:37.905 nim_sdk.py:308] Downloading manifest profile: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:38:37Z INFO: nimlib.nim_sdk - Downloading manifest profile: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-27 18:38:37.939 lib.rs:203] File: special_tokens_map.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-27 18:38:37.939 public.rs:52] Skipping download, using cached copy of file: special_tokens_map.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-27 18:38:37.956 lib.rs:203] File: metadata.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-27 18:38:37.956 public.rs:52] Skipping download, using cached copy of file: metadata.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-27 18:38:37.972 lib.rs:203] File: memory_footprint.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-27 18:38:37.972 public.rs:52] Skipping download, using cached copy of file: memory_footprint.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-27 18:38:37.988 lib.rs:203] File: checksums.blake3 found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
INFO 2026-02-27 18:38:37.988 public.rs:52] Skipping download, using cached copy of file: checksums.blake3 at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
INFO 2026-02-27 18:38:38.004 lib.rs:203] File: tokenizer.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-27 18:38:38.004 public.rs:52] Skipping download, using cached copy of file: tokenizer.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-27 18:38:38.019 lib.rs:203] File: tokenizer_config.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-27 18:38:38.019 public.rs:52] Skipping download, using cached copy of file: tokenizer_config.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-27 18:38:38.035 lib.rs:203] File: model.plan found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/model.plan"
INFO 2026-02-27 18:38:38.035 public.rs:52] Skipping download, using cached copy of file: model.plan at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/model.plan"
INFO 2026-02-27 18:38:38.036 nim_sdk.py:328] Using the workspace specified during init: /opt/nim/workspace
2026-02-27T18:38:38Z INFO: nimlib.nim_sdk - Using the workspace specified during init: /opt/nim/workspace
INFO 2026-02-27 18:38:38.036 nim_sdk.py:341] Materializing workspace to: /opt/nim/workspace
2026-02-27T18:38:38Z INFO: nimlib.nim_sdk - Materializing workspace to: /opt/nim/workspace
INFO 2026-02-27 18:38:42.688 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
INFO 2026-02-27 18:38:45.318 repository.py:154] Loaded tokenizer from /opt/nim/workspace/tokenizer
2026-02-27T18:38:45Z INFO: nemo-retriever-reranking-triton-gen - Loaded tokenizer from /opt/nim/workspace/tokenizer
WARNING 2026-02-27 18:38:57.021 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-27T18:38:57Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-27 18:38:57.021 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-27T18:38:57Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-27 18:38:57.021 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-27T18:38:57Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-27 18:38:57.021 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-27T18:38:57Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-27 18:38:57.022 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-27T18:38:57Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-27 18:38:57.022 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-27T18:38:57Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-27 18:38:57.022 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-27T18:38:57Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
INFO 2026-02-27 18:38:57.119 tensor_rt_model_builder.py:151] Available TRT engine profiles: 
  - (max_batch_size=1, max_seq_length=8192)
  - (max_batch_size=8, max_seq_length=8192)
  - (max_batch_size=16, max_seq_length=8192)
  - (max_batch_size=30, max_seq_length=8192)
  - (max_batch_size=30, max_seq_length=1024)
  - (max_batch_size=30, max_seq_length=2048)
  - (max_batch_size=30, max_seq_length=4096)
2026-02-27T18:38:57Z INFO: nemo-retriever-reranking-triton-gen - Available TRT engine profiles: 
  - (max_batch_size=1, max_seq_length=8192)
  - (max_batch_size=8, max_seq_length=8192)
  - (max_batch_size=16, max_seq_length=8192)
  - (max_batch_size=30, max_seq_length=8192)
  - (max_batch_size=30, max_seq_length=1024)
  - (max_batch_size=30, max_seq_length=2048)
  - (max_batch_size=30, max_seq_length=4096)
INFO 2026-02-27 18:38:57.119 repository.py:256] Selected TensorRT engine profile: profile_index=3 inputs=[TensorInfo(name='input_ids', dtype='int64', shape=(-1, -1), opt_shapes=(16, 512), max_shapes=(30, 8192), min_shapes=(1, 2)), TensorInfo(name='attention_mask', dtype='int64', shape=(-1, -1), opt_shapes=(16, 512), max_shapes=(30, 8192), min_shapes=(1, 2))] outputs=[TensorInfo(name='logits', dtype='float32', shape=(1, 1), opt_shapes=(), max_shapes=(), min_shapes=())]
2026-02-27T18:38:57Z INFO: nemo-retriever-reranking-triton-gen - Selected TensorRT engine profile: profile_index=3 inputs=[TensorInfo(name='input_ids', dtype='int64', shape=(-1, -1), opt_shapes=(16, 512), max_shapes=(30, 8192), min_shapes=(1, 2)), TensorInfo(name='attention_mask', dtype='int64', shape=(-1, -1), opt_shapes=(16, 512), max_shapes=(30, 8192), min_shapes=(1, 2))] outputs=[TensorInfo(name='logits', dtype='float32', shape=(1, 1), opt_shapes=(), max_shapes=(), min_shapes=())]
INFO 2026-02-27 18:38:57.122 tensor_rt_model_builder.py:228] Setting number of models for '_nvidia_llama_3_2_nv_rerankqa_1b_v2_model' to: 1
2026-02-27T18:38:57Z INFO: nemo-retriever-reranking-triton-gen - Setting number of models for '_nvidia_llama_3_2_nv_rerankqa_1b_v2_model' to: 1
INFO 2026-02-27 18:38:57.123 tensor_rt_model_builder.py:231] Using TensorRT max_batch_size: 30
2026-02-27T18:38:57Z INFO: nemo-retriever-reranking-triton-gen - Using TensorRT max_batch_size: 30
INFO 2026-02-27 18:38:57.124 tensor_rt_model_builder.py:244] Python model successfully generated and written to: /opt/nim/tmp/run/triton-model-repository/_nvidia_llama_3_2_nv_rerankqa_1b_v2_model/1/model.py
2026-02-27T18:38:57Z INFO: nemo-retriever-reranking-triton-gen - Python model successfully generated and written to: /opt/nim/tmp/run/triton-model-repository/_nvidia_llama_3_2_nv_rerankqa_1b_v2_model/1/model.py
INFO 2026-02-27 18:38:57.372 bls_model_builder.py:75] BLS model successfully generated and written to: /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/model.py
2026-02-27T18:38:57Z INFO: nemo-retriever-reranking-triton-gen - BLS model successfully generated and written to: /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/model.py
INFO 2026-02-27 18:38:57.404 repository.py:529] Successfully saved model service config to /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-27T18:38:57Z INFO: nemo-retriever-reranking-triton-gen - Successfully saved model service config to /opt/nim/tmp/run/triton-model-repository/service_config.yaml
INFO 2026-02-27 18:38:57.404 repository.py:531] Sucessfully generated Triton Model Repository at /opt/nim/tmp/run/triton-model-repository
2026-02-27T18:38:57Z INFO: nemo-retriever-reranking-triton-gen - Sucessfully generated Triton Model Repository at /opt/nim/tmp/run/triton-model-repository
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
INFO 2026-02-27 18:38:58.110 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
2026-02-27T18:38:58Z INFO: nimlib - Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
I0227 18:38:58.259723 253 pinned_memory_manager.cc:277] "Pinned memory pool is created at '0x204c00000' with size 268435456"
I0227 18:38:58.259846 253 cuda_memory_manager.cc:107] "CUDA memory pool is created on device 0 with size 67108864"
I0227 18:38:58.275435 253 model_lifecycle.cc:473] "loading: _nvidia_llama_3_2_nv_rerankqa_1b_v2_model:1"
I0227 18:38:58.275527 253 model_lifecycle.cc:473] "loading: nvidia_llama_3_2_nv_rerankqa_1b_v2:1"
I0227 18:38:58.334455 253 tensorrt.cc:65] "TRITONBACKEND_Initialize: tensorrt"
I0227 18:38:58.334514 253 tensorrt.cc:75] "Triton TRITONBACKEND API version: 1.19"
I0227 18:38:58.334524 253 tensorrt.cc:81] "'tensorrt' TRITONBACKEND API version: 1.19"
I0227 18:38:58.334549 253 tensorrt.cc:105] "backend configuration:\n{\"cmdline\":{\"auto-complete-config\":\"true\",\"backend-directory\":\"/opt/tritonserver/backends\",\"min-compute-capability\":\"6.000000\",\"version-compatible\":\"true\",\"default-max-batch-size\":\"4\"}}"
I0227 18:38:58.335669 253 tensorrt.cc:231] "TRITONBACKEND_ModelInitialize: _nvidia_llama_3_2_nv_rerankqa_1b_v2_model (version 1)"
INFO 2026-02-27 18:38:58.582 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-27 18:38:58.603 http_api.py:52] Serving endpoints:
  0.0.0.0:8000/v1/triton-inference-statistics (GET)
  0.0.0.0:8000/v1/models (GET)
  0.0.0.0:8000/v1/ranking (POST)
  0.0.0.0:8000/v1/health/live (GET)
  0.0.0.0:8000/v1/health/ready (GET)
  0.0.0.0:8000/v1/metrics (GET)
  0.0.0.0:8000/v1/license (GET)
  0.0.0.0:8000/v1/metadata (GET)
  0.0.0.0:8000/v1/manifest (GET)
2026-02-27T18:38:58Z INFO: nimlib.nim_inference_api_builder.api - Serving endpoints:
  0.0.0.0:8000/v1/triton-inference-statistics (GET)
  0.0.0.0:8000/v1/models (GET)
  0.0.0.0:8000/v1/ranking (POST)
  0.0.0.0:8000/v1/health/live (GET)
  0.0.0.0:8000/v1/health/ready (GET)
  0.0.0.0:8000/v1/metrics (GET)
  0.0.0.0:8000/v1/license (GET)
  0.0.0.0:8000/v1/metadata (GET)
  0.0.0.0:8000/v1/manifest (GET)
INFO 2026-02-27 18:38:58.603 http_api.py:73] {'message': 'Starting HTTP Inference server', 'port': 8000, 'workers_count': 8, 'host': '0.0.0.0', 'log_level': 'info', 'SSL': 'disabled'}
2026-02-27T18:38:58Z INFO: nimlib.nim_inference_api_builder.api - {'message': 'Starting HTTP Inference server', 'port': 8000, 'workers_count': 8, 'host': '0.0.0.0', 'log_level': 'info', 'SSL': 'disabled'}
2026-02-27T18:38:58Z INFO: uvicorn.error - Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
2026-02-27T18:38:58Z INFO: uvicorn.error - Started parent process [254]
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
2026-02-27T18:39:00Z INFO: uvicorn.error - Started server process [324]
2026-02-27T18:39:00Z INFO: uvicorn.error - Waiting for application startup.
2026-02-27T18:39:00Z INFO: uvicorn.error - Started server process [322]
2026-02-27T18:39:00Z INFO: uvicorn.error - Waiting for application startup.
2026-02-27T18:39:00Z INFO: uvicorn.error - Started server process [325]
2026-02-27T18:39:00Z INFO: uvicorn.error - Waiting for application startup.
2026-02-27T18:39:00Z INFO: uvicorn.error - Started server process [326]
2026-02-27T18:39:00Z INFO: uvicorn.error - Waiting for application startup.
2026-02-27T18:39:00Z INFO: uvicorn.error - Started server process [328]
2026-02-27T18:39:00Z INFO: uvicorn.error - Waiting for application startup.
2026-02-27T18:39:00Z INFO: uvicorn.error - Started server process [327]
2026-02-27T18:39:00Z INFO: uvicorn.error - Waiting for application startup.
2026-02-27T18:39:00Z INFO: uvicorn.error - Started server process [329]
2026-02-27T18:39:00Z INFO: uvicorn.error - Waiting for application startup.
2026-02-27T18:39:00Z INFO: uvicorn.error - Started server process [323]
2026-02-27T18:39:00Z INFO: uvicorn.error - Waiting for application startup.
INFO 2026-02-27 18:39:00.351 profiles.py:98] Registered custom profile selectors: []
2026-02-27T18:39:00Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-27 18:39:00.352 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-27T18:39:00Z INFO: uvicorn.error - Application startup complete.
INFO 2026-02-27 18:39:00.373 profiles.py:98] Registered custom profile selectors: []
2026-02-27T18:39:00Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-27 18:39:00.373 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-27T18:39:00Z INFO: uvicorn.error - Application startup complete.
INFO 2026-02-27 18:39:00.431 profiles.py:98] Registered custom profile selectors: []
2026-02-27T18:39:00Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-27 18:39:00.431 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-27T18:39:00Z INFO: uvicorn.error - Application startup complete.
INFO 2026-02-27 18:39:00.436 profiles.py:98] Registered custom profile selectors: []
2026-02-27T18:39:00Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-27 18:39:00.437 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
INFO 2026-02-27 18:39:00.439 profiles.py:98] Registered custom profile selectors: []
2026-02-27T18:39:00Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-27 18:39:00.439 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-27T18:39:00Z INFO: uvicorn.error - Application startup complete.
2026-02-27T18:39:00Z INFO: uvicorn.error - Application startup complete.
INFO 2026-02-27 18:39:00.451 profiles.py:98] Registered custom profile selectors: []
2026-02-27T18:39:00Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-27 18:39:00.451 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
INFO 2026-02-27 18:39:00.454 profiles.py:98] Registered custom profile selectors: []
2026-02-27T18:39:00Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-27 18:39:00.454 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-27T18:39:00Z INFO: uvicorn.error - Application startup complete.
2026-02-27T18:39:00Z INFO: uvicorn.error - Application startup complete.
INFO 2026-02-27 18:39:00.461 profiles.py:98] Registered custom profile selectors: []
2026-02-27T18:39:00Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-27 18:39:00.461 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-27T18:39:00Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-27T18:39:00Z INFO: uvicorn.error - Application startup complete.
I0227 18:39:02.041550 253 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_0 (CPU device 0)"
I0227 18:39:02.041622 253 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_1 (CPU device 0)"
I0227 18:39:02.041745 253 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_2 (CPU device 0)"
I0227 18:39:02.042096 253 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_4 (CPU device 0)"
I0227 18:39:02.042174 253 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_3 (CPU device 0)"
I0227 18:39:02.042666 253 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_5 (CPU device 0)"
I0227 18:39:02.042857 253 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_6 (CPU device 0)"
I0227 18:39:02.042937 253 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_7 (CPU device 0)"
INFO 2026-02-27 18:39:02.421 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-27 18:39:02.434 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-27 18:39:02.450 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-27 18:39:02.476 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-27 18:39:02.549 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-27 18:39:02.623 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-27 18:39:02.745 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-27 18:39:02.803 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"},"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_7', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"},"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_2', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"},"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_4', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"},"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_6', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"},"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_5', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"},"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_1', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"},"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_3', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"},"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_0', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-27T18:39:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
terminate called after throwing an instance of 'terminate called after throwing an instance of 'boost::interprocess::lock_exception'
boost::interprocess::lock_exception  what():  '
boost::interprocess::lock_exception
  what():  boost::interprocess::lock_exception
I0227 18:40:05.672823 635 pb_stub.cc:2075]  Non-graceful termination detected. 
I0227 18:40:05.673330 645 pb_stub.cc:2075]  I0227 18:40:05.673352 695 pb_stub.cc:2075]  Non-graceful termination detected. 
I0227 18:40:05.673327 680 pb_stub.cc:2075] I0227 18:40:05.673494 712 pb_stub.cc:2075]  Non-graceful termination detected.  
Non-graceful termination detected. 
Non-graceful termination detected. 
I0227 18:40:05.673609 668 pb_stub.cc:2075]  Non-graceful termination detected. 
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-27T18:40:05Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
59  2026-02-28T01:55:13Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T01:55:13Z ERROR: root - Triton service unavailable
2026-02-28T01:55:13Z INFO: uvicorn.access - 172.17.0.1:40796 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T08:34:20Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T08:34:20Z ERROR: root - Triton service unavailable
2026-02-28T08:34:20Z INFO: uvicorn.access - 172.17.0.1:33456 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:07:39Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:07:39Z ERROR: root - Triton service unavailable
2026-02-28T09:07:39Z INFO: uvicorn.access - 172.17.0.1:45962 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:08:35Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:08:35Z ERROR: root - Triton service unavailable
2026-02-28T09:08:35Z INFO: uvicorn.access - 172.17.0.1:46666 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:08:40Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:08:40Z ERROR: root - Triton service unavailable
2026-02-28T09:08:40Z INFO: uvicorn.access - 172.17.0.1:46676 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:08:45Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:08:45Z ERROR: root - Triton service unavailable
2026-02-28T09:08:45Z INFO: uvicorn.access - 172.17.0.1:37140 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:08:50Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:08:50Z ERROR: root - Triton service unavailable
2026-02-28T09:08:50Z INFO: uvicorn.access - 172.17.0.1:37152 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:08:55Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:08:55Z ERROR: root - Triton service unavailable
2026-02-28T09:08:55Z INFO: uvicorn.access - 172.17.0.1:48364 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:00Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:00Z ERROR: root - Triton service unavailable
2026-02-28T09:09:00Z INFO: uvicorn.access - 172.17.0.1:48372 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:05Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:05Z ERROR: root - Triton service unavailable
2026-02-28T09:09:05Z INFO: uvicorn.access - 172.17.0.1:54474 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:10Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:10Z ERROR: root - Triton service unavailable
2026-02-28T09:09:10Z INFO: uvicorn.access - 172.17.0.1:54490 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:15Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:15Z ERROR: root - Triton service unavailable
2026-02-28T09:09:15Z INFO: uvicorn.access - 172.17.0.1:50432 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:20Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:20Z ERROR: root - Triton service unavailable
2026-02-28T09:09:20Z INFO: uvicorn.access - 172.17.0.1:50436 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:25Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:25Z ERROR: root - Triton service unavailable
2026-02-28T09:09:25Z INFO: uvicorn.access - 172.17.0.1:49682 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:30Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:30Z ERROR: root - Triton service unavailable
2026-02-28T09:09:30Z INFO: uvicorn.access - 172.17.0.1:49690 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:35Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:35Z ERROR: root - Triton service unavailable
2026-02-28T09:09:35Z INFO: uvicorn.access - 172.17.0.1:41396 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:40Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:40Z ERROR: root - Triton service unavailable
2026-02-28T09:09:40Z INFO: uvicorn.access - 172.17.0.1:41412 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:45Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:45Z ERROR: root - Triton service unavailable
2026-02-28T09:09:45Z INFO: uvicorn.access - 172.17.0.1:51928 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:50Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:50Z ERROR: root - Triton service unavailable
2026-02-28T09:09:50Z INFO: uvicorn.access - 172.17.0.1:51942 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:09:55Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:09:55Z ERROR: root - Triton service unavailable
2026-02-28T09:09:55Z INFO: uvicorn.access - 172.17.0.1:37074 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:00Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:00Z ERROR: root - Triton service unavailable
2026-02-28T09:10:00Z INFO: uvicorn.access - 172.17.0.1:37078 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:05Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:05Z ERROR: root - Triton service unavailable
2026-02-28T09:10:05Z INFO: uvicorn.access - 172.17.0.1:35840 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:10Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:10Z ERROR: root - Triton service unavailable
2026-02-28T09:10:10Z INFO: uvicorn.access - 172.17.0.1:35842 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:15Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:15Z ERROR: root - Triton service unavailable
2026-02-28T09:10:15Z INFO: uvicorn.access - 172.17.0.1:51590 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:20Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:20Z ERROR: root - Triton service unavailable
2026-02-28T09:10:20Z INFO: uvicorn.access - 172.17.0.1:51598 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:26Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:26Z ERROR: root - Triton service unavailable
2026-02-28T09:10:26Z INFO: uvicorn.access - 172.17.0.1:55750 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:31Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:31Z ERROR: root - Triton service unavailable
2026-02-28T09:10:31Z INFO: uvicorn.access - 172.17.0.1:55764 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:36Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:36Z ERROR: root - Triton service unavailable
2026-02-28T09:10:36Z INFO: uvicorn.access - 172.17.0.1:47606 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:41Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:41Z ERROR: root - Triton service unavailable
2026-02-28T09:10:41Z INFO: uvicorn.access - 172.17.0.1:47608 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:46Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:46Z ERROR: root - Triton service unavailable
2026-02-28T09:10:46Z INFO: uvicorn.access - 172.17.0.1:32958 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:51Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:51Z ERROR: root - Triton service unavailable
2026-02-28T09:10:51Z INFO: uvicorn.access - 172.17.0.1:32974 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:10:56Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:10:56Z ERROR: root - Triton service unavailable
2026-02-28T09:10:56Z INFO: uvicorn.access - 172.17.0.1:37098 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:01Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:01Z ERROR: root - Triton service unavailable
2026-02-28T09:11:01Z INFO: uvicorn.access - 172.17.0.1:37102 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:06Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:06Z ERROR: root - Triton service unavailable
2026-02-28T09:11:06Z INFO: uvicorn.access - 172.17.0.1:47900 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:11Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:11Z ERROR: root - Triton service unavailable
2026-02-28T09:11:11Z INFO: uvicorn.access - 172.17.0.1:47914 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:16Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:16Z ERROR: root - Triton service unavailable
2026-02-28T09:11:16Z INFO: uvicorn.access - 172.17.0.1:56956 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:21Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:21Z ERROR: root - Triton service unavailable
2026-02-28T09:11:21Z INFO: uvicorn.access - 172.17.0.1:56960 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:26Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:26Z ERROR: root - Triton service unavailable
2026-02-28T09:11:26Z INFO: uvicorn.access - 172.17.0.1:33496 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:31Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:31Z ERROR: root - Triton service unavailable
2026-02-28T09:11:31Z INFO: uvicorn.access - 172.17.0.1:33512 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:36Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:36Z ERROR: root - Triton service unavailable
2026-02-28T09:11:36Z INFO: uvicorn.access - 172.17.0.1:46696 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:41Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:41Z ERROR: root - Triton service unavailable
2026-02-28T09:11:41Z INFO: uvicorn.access - 172.17.0.1:46704 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:46Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:46Z ERROR: root - Triton service unavailable
2026-02-28T09:11:46Z INFO: uvicorn.access - 172.17.0.1:54634 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:46Z INFO: uvicorn.access - 172.17.0.1:54648 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:11:46Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:46Z ERROR: root - Triton service unavailable
2026-02-28T09:11:46Z INFO: uvicorn.access - 172.17.0.1:54656 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:51Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:51Z ERROR: root - Triton service unavailable
2026-02-28T09:11:51Z INFO: uvicorn.access - 172.17.0.1:54660 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:11:56Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:11:56Z ERROR: root - Triton service unavailable
2026-02-28T09:11:56Z INFO: uvicorn.access - 172.17.0.1:41446 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:01Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:01Z ERROR: root - Triton service unavailable
2026-02-28T09:12:01Z INFO: uvicorn.access - 172.17.0.1:41448 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:06Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:06Z ERROR: root - Triton service unavailable
2026-02-28T09:12:06Z INFO: uvicorn.access - 172.17.0.1:49264 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:11Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:11Z ERROR: root - Triton service unavailable
2026-02-28T09:12:11Z INFO: uvicorn.access - 172.17.0.1:49274 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:16Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:16Z ERROR: root - Triton service unavailable
2026-02-28T09:12:16Z INFO: uvicorn.access - 172.17.0.1:50708 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:21Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:21Z ERROR: root - Triton service unavailable
2026-02-28T09:12:21Z INFO: uvicorn.access - 172.17.0.1:50716 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:26Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:26Z ERROR: root - Triton service unavailable
2026-02-28T09:12:26Z INFO: uvicorn.access - 172.17.0.1:33310 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:31Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:31Z ERROR: root - Triton service unavailable
2026-02-28T09:12:31Z INFO: uvicorn.access - 172.17.0.1:33326 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:36Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:36Z ERROR: root - Triton service unavailable
2026-02-28T09:12:36Z INFO: uvicorn.access - 172.17.0.1:53952 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:41Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:41Z ERROR: root - Triton service unavailable
2026-02-28T09:12:41Z INFO: uvicorn.access - 172.17.0.1:53966 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:46Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:46Z ERROR: root - Triton service unavailable
2026-02-28T09:12:46Z INFO: uvicorn.access - 172.17.0.1:49586 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:51Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:51Z ERROR: root - Triton service unavailable
2026-02-28T09:12:51Z INFO: uvicorn.access - 172.17.0.1:49592 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:12:56Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:12:56Z ERROR: root - Triton service unavailable
2026-02-28T09:12:56Z INFO: uvicorn.access - 172.17.0.1:57320 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:13:01Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:13:01Z ERROR: root - Triton service unavailable
2026-02-28T09:13:01Z INFO: uvicorn.access - 172.17.0.1:57328 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:13:06Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:13:06Z ERROR: root - Triton service unavailable
2026-02-28T09:13:06Z INFO: uvicorn.access - 172.17.0.1:33478 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:13:11Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:13:11Z ERROR: root - Triton service unavailable
2026-02-28T09:13:11Z INFO: uvicorn.access - 172.17.0.1:33490 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:13:16Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:13:16Z ERROR: root - Triton service unavailable
2026-02-28T09:13:16Z INFO: uvicorn.access - 172.17.0.1:45482 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:13:21Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:13:21Z ERROR: root - Triton service unavailable
2026-02-28T09:13:21Z INFO: uvicorn.access - 172.17.0.1:45488 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:13:26Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:13:26Z ERROR: root - Triton service unavailable
2026-02-28T09:13:26Z INFO: uvicorn.access - 172.17.0.1:57688 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:13:31Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:13:31Z ERROR: root - Triton service unavailable
2026-02-28T09:13:31Z INFO: uvicorn.access - 172.17.0.1:57702 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:13:36Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:13:36Z ERROR: root - Triton service unavailable
2026-02-28T09:13:36Z INFO: uvicorn.access - 172.17.0.1:47350 - "POST /v1/ranking HTTP/1.1" 503
2026-02-28T09:17:35Z ERROR: root - Got error from Triton: failed to connect to all addresses; last error: UNKNOWN: ipv4:127.0.0.1:8001: Failed to connect to remote host: connect: Connection refused (111)
2026-02-28T09:17:35Z ERROR: root - Triton service unavailable
2026-02-28T09:17:35Z INFO: uvicorn.access - 172.17.0.1:34546 - "POST /v1/ranking HTTP/1.1" 503

===================================
== NVIDIA NIM for Text Reranking ==
===================================

NVIDIA Release 1.8.0
Model: nvidia/llama-3.2-nv-rerankqa-1b-v2

Container image Copyright (c) 2016-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
The NIM container is governed by the NVIDIA Software License Agreement (found at https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/) and the Product-Specific Terms for NVIDIA AI Products (found at https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/).

Use of this model is governed by the NVIDIA Community Model License Agreement (found at https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-community-models-license/).

ADDITIONAL INFORMATION: Llama 3.2 Community License Agreement (https://www.llama.com/llama3_2/license/). Built with Llama.

A copy of this license can be found under /opt/nim/LICENSE.
Third Party Software Attributions and Licenses can be found under /opt/nim/acknowledgements.txt.

Overriding NIM_LOG_LEVEL: replacing NIM_LOG_LEVEL=unset with NIM_LOG_LEVEL=INFO
HF_HOME is set to /opt/nim/.cache/huggingface
INFO 2026-02-28 09:17:57.980 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/opt/nim/start_server.d', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
NIM_MODEL_PROFILE is set to bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:17:58.907 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/opt/nim/start_server.d', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
INFO 2026-02-28 09:18:02.252 profiles.py:98] Registered custom profile selectors: []
INFO 2026-02-28 09:18:02.252 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:02.252 nim_sdk.py:299] Using the profile selected by the profile selector: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:02.252 nim_sdk.py:308] Downloading manifest profile: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:02.319 lib.rs:203] File: tokenizer.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-28 09:18:02.319 public.rs:52] Skipping download, using cached copy of file: tokenizer.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-28 09:18:02.337 lib.rs:203] File: special_tokens_map.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-28 09:18:02.338 public.rs:52] Skipping download, using cached copy of file: special_tokens_map.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-28 09:18:02.351 lib.rs:203] File: checksums.blake3 found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
INFO 2026-02-28 09:18:02.351 public.rs:52] Skipping download, using cached copy of file: checksums.blake3 at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
INFO 2026-02-28 09:18:02.364 lib.rs:203] File: model.plan found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/model.plan"
INFO 2026-02-28 09:18:02.364 public.rs:52] Skipping download, using cached copy of file: model.plan at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/model.plan"
INFO 2026-02-28 09:18:02.378 lib.rs:203] File: memory_footprint.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-28 09:18:02.378 public.rs:52] Skipping download, using cached copy of file: memory_footprint.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-28 09:18:02.392 lib.rs:203] File: tokenizer_config.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-28 09:18:02.392 public.rs:52] Skipping download, using cached copy of file: tokenizer_config.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-28 09:18:02.405 lib.rs:203] File: metadata.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-28 09:18:02.405 public.rs:52] Skipping download, using cached copy of file: metadata.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-28 09:18:02.406 nim_sdk.py:328] Using the workspace specified during init: /opt/nim/workspace
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
INFO 2026-02-28 09:18:07.522 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
2026-02-28T09:18:07Z INFO: nimlib - Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
INFO 2026-02-28 09:18:07.766 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:07Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:07.767 nim_sdk.py:294] Using the profile specified by the user: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:07Z INFO: nimlib.nim_sdk - Using the profile specified by the user: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:07.767 nim_sdk.py:308] Downloading manifest profile: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:07Z INFO: nimlib.nim_sdk - Downloading manifest profile: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:07.787 lib.rs:203] File: metadata.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-28 09:18:07.787 public.rs:52] Skipping download, using cached copy of file: metadata.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-28 09:18:07.803 lib.rs:203] File: model.plan found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/model.plan"
INFO 2026-02-28 09:18:07.803 public.rs:52] Skipping download, using cached copy of file: model.plan at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/model.plan"
INFO 2026-02-28 09:18:07.819 lib.rs:203] File: special_tokens_map.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-28 09:18:07.819 public.rs:52] Skipping download, using cached copy of file: special_tokens_map.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-28 09:18:07.835 lib.rs:203] File: checksums.blake3 found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
INFO 2026-02-28 09:18:07.835 public.rs:52] Skipping download, using cached copy of file: checksums.blake3 at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
INFO 2026-02-28 09:18:07.850 lib.rs:203] File: tokenizer.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-28 09:18:07.850 public.rs:52] Skipping download, using cached copy of file: tokenizer.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-28 09:18:07.865 lib.rs:203] File: tokenizer_config.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-28 09:18:07.865 public.rs:52] Skipping download, using cached copy of file: tokenizer_config.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-28 09:18:07.881 lib.rs:203] File: memory_footprint.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-28 09:18:07.881 public.rs:52] Skipping download, using cached copy of file: memory_footprint.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-28 09:18:07.882 nim_sdk.py:328] Using the workspace specified during init: /opt/nim/workspace
2026-02-28T09:18:07Z INFO: nimlib.nim_sdk - Using the workspace specified during init: /opt/nim/workspace
INFO 2026-02-28 09:18:07.882 nim_sdk.py:341] Materializing workspace to: /opt/nim/workspace
2026-02-28T09:18:07Z INFO: nimlib.nim_sdk - Materializing workspace to: /opt/nim/workspace
INFO 2026-02-28 09:18:12.968 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
INFO 2026-02-28 09:18:14.996 repository.py:414] Removing contents of directory /opt/nim/tmp/run/triton-model-repository
2026-02-28T09:18:14Z INFO: nemo-retriever-reranking-triton-gen - Removing contents of directory /opt/nim/tmp/run/triton-model-repository

===================================
== NVIDIA NIM for Text Reranking ==
===================================

NVIDIA Release 1.8.0
Model: nvidia/llama-3.2-nv-rerankqa-1b-v2

Container image Copyright (c) 2016-2025, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
The NIM container is governed by the NVIDIA Software License Agreement (found at https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-software-license-agreement/) and the Product-Specific Terms for NVIDIA AI Products (found at https://www.nvidia.com/en-us/agreements/enterprise-software/product-specific-terms-for-ai-products/).

Use of this model is governed by the NVIDIA Community Model License Agreement (found at https://www.nvidia.com/en-us/agreements/enterprise-software/nvidia-community-models-license/).

ADDITIONAL INFORMATION: Llama 3.2 Community License Agreement (https://www.llama.com/llama3_2/license/). Built with Llama.

A copy of this license can be found under /opt/nim/LICENSE.
Third Party Software Attributions and Licenses can be found under /opt/nim/acknowledgements.txt.

Overriding NIM_LOG_LEVEL: replacing NIM_LOG_LEVEL=unset with NIM_LOG_LEVEL=INFO
HF_HOME is set to /opt/nim/.cache/huggingface
INFO 2026-02-28 09:18:16.633 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/opt/nim/start_server.d', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
NIM_MODEL_PROFILE is set to bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:17.038 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/opt/nim/start_server.d', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
INFO 2026-02-28 09:18:17.805 profiles.py:98] Registered custom profile selectors: []
INFO 2026-02-28 09:18:17.805 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:17.805 nim_sdk.py:299] Using the profile selected by the profile selector: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:17.805 nim_sdk.py:308] Downloading manifest profile: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:17.825 lib.rs:203] File: tokenizer.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-28 09:18:17.825 public.rs:52] Skipping download, using cached copy of file: tokenizer.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-28 09:18:17.839 lib.rs:203] File: special_tokens_map.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-28 09:18:17.839 public.rs:52] Skipping download, using cached copy of file: special_tokens_map.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-28 09:18:17.853 lib.rs:203] File: tokenizer_config.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-28 09:18:17.853 public.rs:52] Skipping download, using cached copy of file: tokenizer_config.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-28 09:18:17.866 lib.rs:203] File: checksums.blake3 found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
INFO 2026-02-28 09:18:17.866 public.rs:52] Skipping download, using cached copy of file: checksums.blake3 at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
INFO 2026-02-28 09:18:17.879 lib.rs:203] File: metadata.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-28 09:18:17.879 public.rs:52] Skipping download, using cached copy of file: metadata.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-28 09:18:17.894 lib.rs:203] File: memory_footprint.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-28 09:18:17.894 public.rs:52] Skipping download, using cached copy of file: memory_footprint.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-28 09:18:17.908 lib.rs:203] File: model.plan found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/model.plan"
INFO 2026-02-28 09:18:17.908 public.rs:52] Skipping download, using cached copy of file: model.plan at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/model.plan"
INFO 2026-02-28 09:18:17.908 nim_sdk.py:328] Using the workspace specified during init: /opt/nim/workspace
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
INFO 2026-02-28 09:18:22.771 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
2026-02-28T09:18:22Z INFO: nimlib - Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
INFO 2026-02-28 09:18:22.989 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:22Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:22.989 nim_sdk.py:294] Using the profile specified by the user: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:22Z INFO: nimlib.nim_sdk - Using the profile specified by the user: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:22.989 nim_sdk.py:308] Downloading manifest profile: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:22Z INFO: nimlib.nim_sdk - Downloading manifest profile: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:23.009 lib.rs:203] File: special_tokens_map.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-28 09:18:23.009 public.rs:52] Skipping download, using cached copy of file: special_tokens_map.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/special_tokens_map.json"
INFO 2026-02-28 09:18:23.024 lib.rs:203] File: tokenizer.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-28 09:18:23.024 public.rs:52] Skipping download, using cached copy of file: tokenizer.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer.json"
INFO 2026-02-28 09:18:23.039 lib.rs:203] File: tokenizer_config.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-28 09:18:23.039 public.rs:52] Skipping download, using cached copy of file: tokenizer_config.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/tokenizer-8192-3fe66485/tokenizer_config.json"
INFO 2026-02-28 09:18:23.053 lib.rs:203] File: checksums.blake3 found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
INFO 2026-02-28 09:18:23.053 public.rs:52] Skipping download, using cached copy of file: checksums.blake3 at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/checksums.blake3"
INFO 2026-02-28 09:18:23.067 lib.rs:203] File: metadata.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-28 09:18:23.067 public.rs:52] Skipping download, using cached copy of file: metadata.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/metadata.json"
INFO 2026-02-28 09:18:23.080 lib.rs:203] File: model.plan found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/model.plan"
INFO 2026-02-28 09:18:23.080 public.rs:52] Skipping download, using cached copy of file: model.plan at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/model.plan"
INFO 2026-02-28 09:18:23.093 lib.rs:203] File: memory_footprint.json found in cache: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-28 09:18:23.093 public.rs:52] Skipping download, using cached copy of file: memory_footprint.json at path: "/opt/nim/.cache/ngc/hub/models--nim--nvidia--llama-3.2-nv-rerankqa-1b-v2/snapshots/l40sx1-trt-fp8-lwpgyxqy1w/memory_footprint.json"
INFO 2026-02-28 09:18:23.094 nim_sdk.py:328] Using the workspace specified during init: /opt/nim/workspace
2026-02-28T09:18:23Z INFO: nimlib.nim_sdk - Using the workspace specified during init: /opt/nim/workspace
INFO 2026-02-28 09:18:23.094 nim_sdk.py:341] Materializing workspace to: /opt/nim/workspace
2026-02-28T09:18:23Z INFO: nimlib.nim_sdk - Materializing workspace to: /opt/nim/workspace
INFO 2026-02-28 09:18:27.488 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
INFO 2026-02-28 09:18:29.029 repository.py:154] Loaded tokenizer from /opt/nim/workspace/tokenizer
2026-02-28T09:18:29Z INFO: nemo-retriever-reranking-triton-gen - Loaded tokenizer from /opt/nim/workspace/tokenizer
WARNING 2026-02-28 09:18:42.366 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-28T09:18:42Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-28 09:18:42.367 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-28T09:18:42Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-28 09:18:42.367 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-28T09:18:42Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-28 09:18:42.368 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-28T09:18:42Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-28 09:18:42.368 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-28T09:18:42Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-28 09:18:42.368 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-28T09:18:42Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
WARNING 2026-02-28 09:18:42.368 tensor_rt_model_builder.py:110] Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
2026-02-28T09:18:42Z WARNING: nemo-retriever-reranking-triton-gen - Failed to convert tensor logits profile shapes to tuples, using empty tuples instead
INFO 2026-02-28 09:18:42.467 tensor_rt_model_builder.py:151] Available TRT engine profiles: 
  - (max_batch_size=1, max_seq_length=8192)
  - (max_batch_size=8, max_seq_length=8192)
  - (max_batch_size=16, max_seq_length=8192)
  - (max_batch_size=30, max_seq_length=8192)
  - (max_batch_size=30, max_seq_length=1024)
  - (max_batch_size=30, max_seq_length=2048)
  - (max_batch_size=30, max_seq_length=4096)
2026-02-28T09:18:42Z INFO: nemo-retriever-reranking-triton-gen - Available TRT engine profiles: 
  - (max_batch_size=1, max_seq_length=8192)
  - (max_batch_size=8, max_seq_length=8192)
  - (max_batch_size=16, max_seq_length=8192)
  - (max_batch_size=30, max_seq_length=8192)
  - (max_batch_size=30, max_seq_length=1024)
  - (max_batch_size=30, max_seq_length=2048)
  - (max_batch_size=30, max_seq_length=4096)
INFO 2026-02-28 09:18:42.468 repository.py:256] Selected TensorRT engine profile: profile_index=3 inputs=[TensorInfo(name='input_ids', dtype='int64', shape=(-1, -1), opt_shapes=(16, 512), max_shapes=(30, 8192), min_shapes=(1, 2)), TensorInfo(name='attention_mask', dtype='int64', shape=(-1, -1), opt_shapes=(16, 512), max_shapes=(30, 8192), min_shapes=(1, 2))] outputs=[TensorInfo(name='logits', dtype='float32', shape=(1, 1), opt_shapes=(), max_shapes=(), min_shapes=())]
2026-02-28T09:18:42Z INFO: nemo-retriever-reranking-triton-gen - Selected TensorRT engine profile: profile_index=3 inputs=[TensorInfo(name='input_ids', dtype='int64', shape=(-1, -1), opt_shapes=(16, 512), max_shapes=(30, 8192), min_shapes=(1, 2)), TensorInfo(name='attention_mask', dtype='int64', shape=(-1, -1), opt_shapes=(16, 512), max_shapes=(30, 8192), min_shapes=(1, 2))] outputs=[TensorInfo(name='logits', dtype='float32', shape=(1, 1), opt_shapes=(), max_shapes=(), min_shapes=())]
INFO 2026-02-28 09:18:42.469 tensor_rt_model_builder.py:228] Setting number of models for '_nvidia_llama_3_2_nv_rerankqa_1b_v2_model' to: 1
2026-02-28T09:18:42Z INFO: nemo-retriever-reranking-triton-gen - Setting number of models for '_nvidia_llama_3_2_nv_rerankqa_1b_v2_model' to: 1
INFO 2026-02-28 09:18:42.469 tensor_rt_model_builder.py:231] Using TensorRT max_batch_size: 30
2026-02-28T09:18:42Z INFO: nemo-retriever-reranking-triton-gen - Using TensorRT max_batch_size: 30
INFO 2026-02-28 09:18:42.470 tensor_rt_model_builder.py:244] Python model successfully generated and written to: /opt/nim/tmp/run/triton-model-repository/_nvidia_llama_3_2_nv_rerankqa_1b_v2_model/1/model.py
2026-02-28T09:18:42Z INFO: nemo-retriever-reranking-triton-gen - Python model successfully generated and written to: /opt/nim/tmp/run/triton-model-repository/_nvidia_llama_3_2_nv_rerankqa_1b_v2_model/1/model.py
INFO 2026-02-28 09:18:42.729 bls_model_builder.py:75] BLS model successfully generated and written to: /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/model.py
2026-02-28T09:18:42Z INFO: nemo-retriever-reranking-triton-gen - BLS model successfully generated and written to: /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/model.py
INFO 2026-02-28 09:18:42.771 repository.py:529] Successfully saved model service config to /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-28T09:18:42Z INFO: nemo-retriever-reranking-triton-gen - Successfully saved model service config to /opt/nim/tmp/run/triton-model-repository/service_config.yaml
INFO 2026-02-28 09:18:42.772 repository.py:531] Sucessfully generated Triton Model Repository at /opt/nim/tmp/run/triton-model-repository
2026-02-28T09:18:42Z INFO: nemo-retriever-reranking-triton-gen - Sucessfully generated Triton Model Repository at /opt/nim/tmp/run/triton-model-repository
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
INFO 2026-02-28 09:18:43.608 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
2026-02-28T09:18:43Z INFO: nimlib - Appending: /opt/nim to PYTHONPATH: ['/usr/local/bin', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages']
I0228 09:18:43.709338 246 pinned_memory_manager.cc:277] "Pinned memory pool is created at '0x204c00000' with size 268435456"
I0228 09:18:43.709607 246 cuda_memory_manager.cc:107] "CUDA memory pool is created on device 0 with size 67108864"
I0228 09:18:43.729690 246 model_lifecycle.cc:473] "loading: _nvidia_llama_3_2_nv_rerankqa_1b_v2_model:1"
I0228 09:18:43.729825 246 model_lifecycle.cc:473] "loading: nvidia_llama_3_2_nv_rerankqa_1b_v2:1"
I0228 09:18:43.833024 246 tensorrt.cc:65] "TRITONBACKEND_Initialize: tensorrt"
I0228 09:18:43.833063 246 tensorrt.cc:75] "Triton TRITONBACKEND API version: 1.19"
I0228 09:18:43.833080 246 tensorrt.cc:81] "'tensorrt' TRITONBACKEND API version: 1.19"
I0228 09:18:43.833086 246 tensorrt.cc:105] "backend configuration:\n{\"cmdline\":{\"auto-complete-config\":\"true\",\"backend-directory\":\"/opt/tritonserver/backends\",\"min-compute-capability\":\"6.000000\",\"version-compatible\":\"true\",\"default-max-batch-size\":\"4\"}}"
I0228 09:18:43.834099 246 tensorrt.cc:231] "TRITONBACKEND_ModelInitialize: _nvidia_llama_3_2_nv_rerankqa_1b_v2_model (version 1)"
INFO 2026-02-28 09:18:44.091 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-28 09:18:44.098 http_api.py:52] Serving endpoints:
  0.0.0.0:8000/v1/triton-inference-statistics (GET)
  0.0.0.0:8000/v1/models (GET)
  0.0.0.0:8000/v1/ranking (POST)
  0.0.0.0:8000/v1/health/live (GET)
  0.0.0.0:8000/v1/health/ready (GET)
  0.0.0.0:8000/v1/metrics (GET)
  0.0.0.0:8000/v1/license (GET)
  0.0.0.0:8000/v1/metadata (GET)
  0.0.0.0:8000/v1/manifest (GET)
2026-02-28T09:18:44Z INFO: nimlib.nim_inference_api_builder.api - Serving endpoints:
  0.0.0.0:8000/v1/triton-inference-statistics (GET)
  0.0.0.0:8000/v1/models (GET)
  0.0.0.0:8000/v1/ranking (POST)
  0.0.0.0:8000/v1/health/live (GET)
  0.0.0.0:8000/v1/health/ready (GET)
  0.0.0.0:8000/v1/metrics (GET)
  0.0.0.0:8000/v1/license (GET)
  0.0.0.0:8000/v1/metadata (GET)
  0.0.0.0:8000/v1/manifest (GET)
INFO 2026-02-28 09:18:44.099 http_api.py:73] {'message': 'Starting HTTP Inference server', 'port': 8000, 'workers_count': 8, 'host': '0.0.0.0', 'log_level': 'info', 'SSL': 'disabled'}
2026-02-28T09:18:44Z INFO: nimlib.nim_inference_api_builder.api - {'message': 'Starting HTTP Inference server', 'port': 8000, 'workers_count': 8, 'host': '0.0.0.0', 'log_level': 'info', 'SSL': 'disabled'}
2026-02-28T09:18:44Z INFO: uvicorn.error - Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
2026-02-28T09:18:44Z INFO: uvicorn.error - Started parent process [247]
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
2026-02-28T09:18:45Z INFO: uvicorn.error - Started server process [318]
2026-02-28T09:18:45Z INFO: uvicorn.error - Waiting for application startup.
2026-02-28T09:18:45Z INFO: uvicorn.error - Started server process [316]
2026-02-28T09:18:45Z INFO: uvicorn.error - Waiting for application startup.
2026-02-28T09:18:45Z INFO: uvicorn.error - Started server process [320]
2026-02-28T09:18:45Z INFO: uvicorn.error - Waiting for application startup.
2026-02-28T09:18:45Z INFO: uvicorn.error - Started server process [317]
2026-02-28T09:18:45Z INFO: uvicorn.error - Waiting for application startup.
2026-02-28T09:18:45Z INFO: uvicorn.error - Started server process [321]
2026-02-28T09:18:45Z INFO: uvicorn.error - Waiting for application startup.
2026-02-28T09:18:45Z INFO: uvicorn.error - Started server process [319]
2026-02-28T09:18:45Z INFO: uvicorn.error - Waiting for application startup.
2026-02-28T09:18:45Z INFO: uvicorn.error - Started server process [315]
2026-02-28T09:18:45Z INFO: uvicorn.error - Waiting for application startup.
2026-02-28T09:18:45Z INFO: uvicorn.error - Started server process [322]
2026-02-28T09:18:45Z INFO: uvicorn.error - Waiting for application startup.
INFO 2026-02-28 09:18:45.858 profiles.py:98] Registered custom profile selectors: []
2026-02-28T09:18:45Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-28 09:18:45.858 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-28T09:18:45Z INFO: uvicorn.error - Application startup complete.
INFO 2026-02-28 09:18:45.921 profiles.py:98] Registered custom profile selectors: []
2026-02-28T09:18:45Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-28 09:18:45.921 profiles.py:98] Registered custom profile selectors: []
2026-02-28T09:18:45Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-28 09:18:45.921 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
INFO 2026-02-28 09:18:45.921 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-28T09:18:45Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-28T09:18:45Z INFO: uvicorn.error - Application startup complete.
2026-02-28T09:18:45Z INFO: uvicorn.error - Application startup complete.
INFO 2026-02-28 09:18:45.942 profiles.py:98] Registered custom profile selectors: []
2026-02-28T09:18:45Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-28 09:18:45.942 profiles.py:98] Registered custom profile selectors: []
INFO 2026-02-28 09:18:45.942 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: nimlib.profiles - Registered custom profile selectors: []
2026-02-28T09:18:45Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
INFO 2026-02-28 09:18:45.942 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-28T09:18:45Z INFO: uvicorn.error - Application startup complete.
2026-02-28T09:18:45Z INFO: uvicorn.error - Application startup complete.
INFO 2026-02-28 09:18:45.951 profiles.py:98] Registered custom profile selectors: []
2026-02-28T09:18:45Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-28 09:18:45.951 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
INFO 2026-02-28 09:18:45.954 profiles.py:98] Registered custom profile selectors: []
2026-02-28T09:18:45Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-28 09:18:45.954 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-28T09:18:45Z INFO: uvicorn.error - Application startup complete.
INFO 2026-02-28 09:18:45.958 profiles.py:98] Registered custom profile selectors: []
2026-02-28T09:18:45Z INFO: nimlib.profiles - Registered custom profile selectors: []
INFO 2026-02-28 09:18:45.958 profiles.py:208] Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: nimlib.profiles - Matched profile_id in manifest from env NIM_MODEL_PROFILE to: bbf794644e63fe68abeffb0dae1c4f734122ace0350f827c8935cc75e80df265
2026-02-28T09:18:45Z INFO: root - Loading service config from /opt/nim/tmp/run/triton-model-repository/service_config.yaml
2026-02-28T09:18:45Z INFO: uvicorn.error - Application startup complete.
2026-02-28T09:18:45Z INFO: uvicorn.error - Application startup complete.
I0228 09:18:47.476044 246 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_0 (CPU device 0)"
I0228 09:18:47.476218 246 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_1 (CPU device 0)"
I0228 09:18:47.476398 246 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_3 (CPU device 0)"
I0228 09:18:47.476566 246 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_4 (CPU device 0)"
I0228 09:18:47.476659 246 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_2 (CPU device 0)"
I0228 09:18:47.476775 246 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_5 (CPU device 0)"
I0228 09:18:47.476871 246 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_6 (CPU device 0)"
I0228 09:18:47.476981 246 python_be.cc:2289] "TRITONBACKEND_ModelInstanceInitialize: nvidia_llama_3_2_nv_rerankqa_1b_v2_0_7 (CPU device 0)"
INFO 2026-02-28 09:18:47.829 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-28 09:18:47.836 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-28 09:18:47.855 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-28 09:18:47.880 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-28 09:18:47.963 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-28 09:18:48.030 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-28 09:18:48.104 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
INFO 2026-02-28 09:18:48.111 __init__.py:413] Appending: /opt/nim to PYTHONPATH: ['', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1', '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', '/opt/tritonserver/backends/python']
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
OTEL Logging handler requested, but Python logging auto-instrumentation not set up. Set OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true to enable logging auto-instrumentation.
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"},"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_0', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"},"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_2', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"},"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_7', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"},"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_6', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"},"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_5', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"},"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_4', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"},"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_1', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Initializing RerankingBlsModel with args: {'model_config': '{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2","platform":"","backend":"python","runtime":"","version_policy":{"latest":{"num_versions":1}},"max_batch_size":0,"input":[{"name":"query","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false},{"name":"passage","data_type":"TYPE_STRING","format":"FORMAT_NONE","dims":[-1],"is_shape_tensor":false,"allow_ragged_batch":false,"optional":false,"is_non_linear_format_io":false}],"output":[{"name":"index","data_type":"TYPE_INT32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"logit","data_type":"TYPE_FP32","dims":[-1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false},{"name":"token_count","data_type":"TYPE_INT32","dims":[1],"label_filename":"","is_shape_tensor":false,"is_non_linear_format_io":false}],"batch_input":[],"batch_output":[],"optimization":{"priority":"PRIORITY_DEFAULT","input_pinned_memory":{"enable":true},"output_pinned_memory":{"enable":true},"gather_kernel_buffer_threshold":0,"eager_batching":false},"dynamic_batching":{"preferred_batch_size":[],"max_queue_delay_microseconds":100,"preserve_ordering":false,"priority_levels":0,"default_priority_level":0,"priority_queue_policy":{}},"instance_group":[{"name":"nvidia_llama_3_2_nv_rerankqa_1b_v2_0","kind":"KIND_CPU","count":8,"gpus":[],"secondary_devices":[],"profile":[],"passive":false,"host_policy":""}],"default_model_filename":"model.py","cc_model_filenames":{},"metric_tags":{},"parameters":{"reranking_model_name":{"string_value":"_nvidia_llama_3_2_nv_rerankqa_1b_v2_model"},"tokenizer_template":{"string_value":"question:{query} \\n \\n passage:{passage}"}},"model_warmup":[]}', 'model_instance_kind': 'CPU', 'model_instance_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2_0_3', 'model_instance_device_id': '0', 'model_repository': '/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2', 'model_version': '1', 'model_name': 'nvidia_llama_3_2_nv_rerankqa_1b_v2'}
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Bls config: hf_model=None base_path=None tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None reranking_model_name='_nvidia_llama_3_2_nv_rerankqa_1b_v2_model'
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.bls - Tokenizer config: hf_model=None base_path=PosixPath('/opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1') tokenizer_path=None tokenizer_template='question:{query} \n \n passage:{passage}' max_seq_length=None
2026-02-28T09:18:49Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Loading tokenizer from /opt/nim/tmp/run/triton-model-repository/nvidia_llama_3_2_nv_rerankqa_1b_v2/1/tokenizer
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - Tokenizer is fast: True
2026-02-28T09:18:53Z INFO: nemo_retriever_reranking_triton_gen.tools.tokenizer - tokenizer.model_max_length: 8192
I0228 09:18:53.471530 246 model_lifecycle.cc:849] "successfully loaded 'nvidia_llama_3_2_nv_rerankqa_1b_v2'"
2026-02-28T09:18:56Z INFO: uvicorn.access - 172.17.0.1:48456 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:19:01Z INFO: uvicorn.access - 172.17.0.1:48460 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:19:08Z INFO: uvicorn.access - 172.17.0.1:48460 - "GET /v1/health/ready HTTP/1.1" 503
I0228 09:19:09.275366 711 pb_stub.cc:2075]  Non-graceful termination detected. I0228 09:19:09.275369 695 pb_stub.cc:2075] 
I0228 09:19:09.275363 647 pb_stub.cc:2075] I0228 09:19:09.275364 629 pb_stub.cc:2075]  I0228 09:19:09.275353 678 pb_stub.cc:2075] I0228 09:19:09.275380 661 pb_stub.cc:2075] I0228 09:19:09.275362 628 pb_stub.cc:2075] Non-graceful termination detected.  I0228 09:19:09.275384 638 pb_stub.cc:2075]    
 Non-graceful termination detected. Non-graceful termination detected. Non-graceful termination detected. Non-graceful termination detected.  Non-graceful termination detected. 



Non-graceful termination detected. 

2026-02-28T09:19:13Z INFO: uvicorn.access - 172.17.0.1:52818 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:19:18Z INFO: uvicorn.access - 172.17.0.1:52820 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:19:23Z INFO: uvicorn.access - 172.17.0.1:38652 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:19:28Z INFO: uvicorn.access - 172.17.0.1:38668 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:19:33Z INFO: uvicorn.access - 172.17.0.1:47402 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:19:38Z INFO: uvicorn.access - 172.17.0.1:47404 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:19:43Z INFO: uvicorn.access - 172.17.0.1:48592 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:19:48Z INFO: uvicorn.access - 172.17.0.1:48606 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:19:53Z INFO: uvicorn.access - 172.17.0.1:46650 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:19:58Z INFO: uvicorn.access - 172.17.0.1:46662 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:20:03Z INFO: uvicorn.access - 172.17.0.1:54818 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:20:09Z INFO: uvicorn.access - 172.17.0.1:54826 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:20:14Z INFO: uvicorn.access - 172.17.0.1:49038 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:20:19Z INFO: uvicorn.access - 172.17.0.1:49040 - "GET /v1/health/ready HTTP/1.1" 503
2026-02-28T09:20:24Z INFO: uvicorn.access - 172.17.0.1:43140 - "GET /v1/health/ready HTTP/1.1" 503
